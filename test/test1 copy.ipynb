{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex, PromptTemplate,get_response_synthesizer,Settings\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = \"chroma_llama1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miriy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "llm = Groq(model=\"llama3-8b-8192\")\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = chromadb.PersistentClient(path=CHROMA_PATH)  # Make sure this is correctly used.\n",
    "    # get collection\n",
    "chroma_collection = db.get_or_create_collection(\"document_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_vector_store(\n",
    "        vector_store, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='1a1ebf7b-0ae3-40cf-b6a3-ae3de3373540', embedding=None, metadata={'page_label': '198', 'file_name': 'THE_NATURAL_LANGUAGE_PROCESSING_WORKSHOP.pdf', 'file_path': 'd:\\\\Python\\\\university_chatbot\\\\data\\\\THE_NATURAL_LANGUAGE_PROCESSING_WORKSHOP.pdf', 'file_type': 'application/pdf', 'file_size': 59957721, 'creation_date': '2024-09-02', 'last_modified_date': '2024-08-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='6aceb4bd-ac8f-45f8-9b04-fa07206cb825', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '198', 'file_name': 'THE_NATURAL_LANGUAGE_PROCESSING_WORKSHOP.pdf', 'file_path': 'd:\\\\Python\\\\university_chatbot\\\\data\\\\THE_NATURAL_LANGUAGE_PROCESSING_WORKSHOP.pdf', 'file_type': 'application/pdf', 'file_size': 59957721, 'creation_date': '2024-09-02', 'last_modified_date': '2024-08-22'}, hash='8b70d9cc39a6fd5596bdc37404f3a1de89abc611fed2db96bb785cf9cbe92a1a')}, text='198 | Developing a Text Classifier\\nSummary\\nIn this chapter, you learned about the different types of machine learning techniques, \\nsuch as supervised and unsupervised learning. We explored unsupervised algorithms \\nsuch as hierarchical clustering and k-means clustering, and supervised learning \\nalgorithms, such as k-nearest neighbor, the Naive Bayes classifier, and tree-based \\nmethods, such as random forest and XGBoost, that can perform both regression and \\nclassification. We discussed the need for sampling and went over different kinds of \\nsampling techniques for splitting a given dataset into training and validation sets. \\nFinally, we covered the process of saving a model on the hard disk and loading it back \\ninto memory for future use.\\nIn the next chapter, you will learn about several techniques that you can use to collect \\ndata from various sources.', mimetype='text/plain', start_char_idx=0, end_char_idx=864, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.2834018198713199),\n",
       " NodeWithScore(node=TextNode(id_='bdb17fec-1ba1-4e54-83a8-5a28767e9902', embedding=None, metadata={'page_label': '37', 'file_name': 'THE_NATURAL_LANGUAGE_PROCESSING_WORKSHOP.pdf', 'file_path': 'd:\\\\Python\\\\university_chatbot\\\\data\\\\THE_NATURAL_LANGUAGE_PROCESSING_WORKSHOP.pdf', 'file_type': 'application/pdf', 'file_size': 59957721, 'creation_date': '2024-09-02', 'last_modified_date': '2024-08-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='0a5b464f-e9b3-4a94-9c2d-a2b5e35ab6f8', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '37', 'file_name': 'THE_NATURAL_LANGUAGE_PROCESSING_WORKSHOP.pdf', 'file_path': 'd:\\\\Python\\\\university_chatbot\\\\data\\\\THE_NATURAL_LANGUAGE_PROCESSING_WORKSHOP.pdf', 'file_type': 'application/pdf', 'file_size': 59957721, 'creation_date': '2024-09-02', 'last_modified_date': '2024-08-22'}, hash='d380ee1b71d2281397bd9849e302fbafb2fa8567eb6e1bd5902d343aef427827')}, text='Types of Data | 37\\nCategorizing Data Based on Structure\\nData can be divided on the basis of structure into three categories, namely, \\nstructured, semi-structured, and unstructured data, as shown in the  \\nfollowing diagram:\\nFigure 2.1: Categorization based on content\\nThese three categories are as follows:\\nâ€¢ Structured data : This is the most organized form of data. It is represented in \\ntabular formats such as Excel files and Comma-Separated Value  (CSV) files. The \\nfollowing image shows what structured data usually looks like:\\nFigure 2.2: Structured data\\nThe preceding table contains information about five people, with each row \\nrepresenting a person and each column representing one of their attributes.', mimetype='text/plain', start_char_idx=0, end_char_idx=711, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.2732897710533761)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = index.as_retriever()\n",
    "\n",
    "relevant_docs = retriever.retrieve(\"Do you know about data science?\")\n",
    "\n",
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ChainableMixin.as_query_component of <llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x000001DE963C3F10>>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
