{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7-H0kPOG3C-",
    "outputId": "844c3ad8-655b-4f50-c981-85d78d9c4ca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting reportlab\n",
      "  Downloading reportlab-4.2.4-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from PyPDF2) (4.9.0)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.8/dist-packages (from reportlab) (10.2.0)\n",
      "Requirement already satisfied: chardet in /usr/lib/python3/dist-packages (from reportlab) (3.0.4)\n",
      "Installing collected packages: reportlab, PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1 reportlab-4.2.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2 reportlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PGyHeu-TIgpi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning 00_Content_Structure_Data_Analytics_1_2021-10-26_converted.pdf...\n",
      "Cleaning 00_Intro_Data_Analytics_1_converted.pdf...\n",
      "Cleaning 01_-_Introduction_and_Organization_(1)_converted.pdf...\n",
      "Cleaning 01_Introduction_and_Basics_2021-10-26_converted.pdf...\n",
      "Cleaning 01-01_Introduction_and_Scientific_Research_2021-10-26_converted.pdf...\n",
      "Cleaning 01-02_Statistical_Basic_Terms_2021-10-26_converted.pdf...\n",
      "Cleaning 01-03_Data_Aquisition_02-10-2021_converted.pdf...\n",
      "Cleaning 01-03_Statistical_Tools_2021-10-26_converted.pdf...\n",
      "Cleaning 02_-_Linear_Neural_Networks_converted.pdf...\n",
      "Cleaning 02-01-01_Measures_of_Central_Tendency_2021-10-26_converted.pdf...\n",
      "Cleaning 02-01-02_Measures_of_Dispersion_2021-10-26_converted.pdf...\n",
      "Cleaning 02-01-03_Frequencies_2021-10-26_converted.pdf...\n",
      "Cleaning 02-01-04_Variable_Distribution_2021-10-26_converted.pdf...\n",
      "Cleaning 03_-_Multilayer_Neural_Networks_converted.pdf...\n",
      "Cleaning 02-01-06_Population_and_Sample_2021-10-26_converted.pdf...\n",
      "Cleaning 03-01_Knowledge_Discovery_from_Data_2021-10-26_converted.pdf...\n",
      "Cleaning 02-01-05_Hypothesis_Test_2021-10-26_converted.pdf...\n",
      "Cleaning 04_-_Backward_Propagation_converted.pdf...\n",
      "Cleaning 03-02_Frameworks_of_Data_Processing_Models_2021-10-26__converted.pdf...\n",
      "Cleaning 04_Business_Understanding_2021-10-26_converted.pdf...\n",
      "Cleaning 05_-_Improving_Deep_Neural_Networks_converted.pdf...\n",
      "Cleaning 05_Data_Understanding_2021-10-26_converted.pdf...\n",
      "Cleaning 05-01_Data_Collection_converted.pdf...\n",
      "Cleaning 05-01-01_Missing_Data_2021-10-26_converted.pdf...\n",
      "Cleaning 05-01-02_Data_Description_2021-10-26_converted.pdf...\n",
      "Cleaning 05-01-02_Outliers_2021-10-26_converted.pdf...\n",
      "Cleaning 05-01-02-01_Explorative_Data_Description_2021-10-26_converted.pdf...\n",
      "Cleaning 05-01-02-02_Descriptive_Data_Visualization_2021-10-26_converted.pdf...\n",
      "Cleaning 05-01-03_Data_Smoothing_2021-10-26_converted.pdf...\n",
      "Cleaning 05-02_Variable_Engineering_2021-10-26_converted.pdf...\n",
      "Cleaning 05-02-01_Transformation_2021-10-26_converted.pdf...\n",
      "Cleaning 05-02-02_Generating_derived_data_2021-10-26_converted.pdf...\n",
      "Cleaning 05-02-03_Variable_Conversion_2021-10-26_converted.pdf...\n",
      "Cleaning 05-03-01_Analysis_of_Count_Data_2021-10-26_converted.pdf...\n",
      "Cleaning 05-03-01-01_Expected_versus_observed_2021-10-26_converted.pdf...\n",
      "Cleaning 05-03-01-02_Contingency_Table_2021-10-26_converted.pdf...\n",
      "Cleaning 05-03-02-01_Covariance_Analysis_2021-10-26_converted.pdf...\n",
      "Cleaning 05-03-02-02_Correlation_Analysis_2021-10-26_converted.pdf...\n",
      "Cleaning 05-03-02-03_Simple_Regression_2021-10-26_converted.pdf...\n",
      "Cleaning 05-03-03_Techniques_Dimension_Reduction_2021-10-26_converted.pdf...\n",
      "Cleaning 05-03-02-04_Single_Variance_2021-10-26_converted.pdf...\n",
      "Cleaning 06_-_Convolutional_Neural_Networks_converted.pdf...\n",
      "Cleaning 06_Analytical_Methods_-_Categorization_2021-11-10_converted.pdf...\n",
      "Cleaning 07_-_Convnets_in_Practice_converted.pdf...\n",
      "Cleaning 08_-_Transfer_Learning_converted.pdf...\n",
      "Cleaning 09_-_Word_Embedding_converted.pdf...\n",
      "Cleaning 10_-_Recurrent_Neural_Networks_converted.pdf...\n",
      "Cleaning 11_-_Modern_RNNs_converted.pdf...\n",
      "Cleaning A_Recurrent_Latent_Variable_Model_converted.pdf...\n",
      "Cleaning A_Survey_on_Transfer_Learning_converted.pdf...\n",
      "Cleaning A_Survey_on_Negative_Transfer_converted.pdf...\n",
      "Cleaning Ai_Act_Ban_on_social_scoring_converted.pdf...\n",
      "Cleaning An_Empirical_Exploration_of_Recurrent_Network_Architectures_converted.pdf...\n",
      "Cleaning AI-Act-FullText_converted.pdf...\n",
      "Cleaning An_overview_of_gradient_descent_optimization_converted.pdf...\n",
      "Cleaning Analytics_2_Day_4_Text_Preprocesing_converted.pdf...\n",
      "Cleaning Analytics_2_Day_5_Information_Extraction_converted.pdf...\n",
      "Cleaning Analytics_2_Day_8_Language_Models_and_Feature_Engineering_converted.pdf...\n",
      "Cleaning Annexes_converted.pdf...\n",
      "Cleaning Artificial_Intelligence_and_Cybersecurity_Research-1_converted.pdf...\n",
      "Cleaning BERT_-_Pre-training_of_Deep_Bidirectional_Transformers_for_Language_Understanding_converted.pdf...\n",
      "Cleaning Blueprint-for-an-AI-Bill-of-Rights_converted.pdf...\n",
      "Cleaning Class_Assignments_converted.pdf...\n",
      "Cleaning Class_Assignments_Regular_Expressions_converted.pdf...\n",
      "Cleaning communicating-data-with-tableau_(1)_converted.pdf...\n",
      "Cleaning Data_Management_-_1_OpenRefine_Advanced_Task_converted.pdf...\n",
      "Cleaning Data_Management_-_1_Tableau_Prep_Tutorial_converted.pdf...\n",
      "Cleaning Data_Management_-_1_OpenRefine_converted.pdf...\n",
      "Cleaning Data_Storytelling_and_Communication_converted.pdf...\n",
      "Cleaning DataManagement_converted.pdf...\n",
      "Cleaning DataManagement-1_Data_Profiling_converted.pdf...\n",
      "Cleaning Dataviz2_w1_d2_converted.pdf...\n",
      "Cleaning Dataviz2_w1_d1_converted.pdf...\n",
      "Cleaning Design_Basics_converted.pdf...\n",
      "Cleaning Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality_converted.pdf...\n",
      "Cleaning deutsche-normungsroadmap-kuenstliche-intelligenz-ausgabe-2--data(1)_converted.pdf...\n",
      "Cleaning DNR_2019_FINAL_converted.pdf...\n",
      "Cleaning Domain-Adversarial_Training_of_Neural_Networks_converted.pdf...\n",
      "Cleaning DRAW_-_A_Recurrent_Neural_Network_For_Image_Generation_converted.pdf...\n",
      "Cleaning DSA_converted.pdf...\n",
      "Cleaning Echo_Chambers_Filter_Bubbles_and_Polarisation_A_Literature_Review_converted.pdf...\n",
      "Cleaning Efficient_Estimation_of_Word_Representations_in_Vector_Space_converted.pdf...\n",
      "Cleaning ExamAI_Normenuebersicht_2021_04_converted.pdf...\n",
      "Cleaning gitCourse_-_Part1_converted.pdf...\n",
      "Cleaning EfficientNet_-_Rethinking_Model_Scaling_for_Convolutional_Neural_Networks_converted.pdf...\n",
      "Cleaning Learning_long-term_dependencies_with_gradient_descent_is_difficult_converted.pdf...\n",
      "Cleaning Learning_Phrase_Representations_using_RNN_Encoder–Decoder_converted.pdf...\n",
      "Cleaning Learning_Stochastic_Recurrent_Networks_converted.pdf...\n",
      "Cleaning learningtableau2020_V2_converted.pdf...\n",
      "Cleaning Lecture_Notes-Prof._Olena_Linnyk.2021_converted.pdf...\n",
      "Cleaning Liu_et_al_2021_-_ML-Doctor_converted.pdf...\n",
      "Cleaning Long_Short-Term_Memory_converted.pdf...\n",
      "Cleaning IEEE_7010_A_New_Standard_for_Assessing_the_Well-be_converted.pdf...\n",
      "Cleaning How_transferable_are_features_in_deep_neural_networks_converted.pdf...\n",
      "Cleaning HBR-_Regulation_is_Coming_converted.pdf...\n",
      "Cleaning Grid_Long_Short-Term_Memory_converted.pdf...\n",
      "Cleaning GloVe_-_Global_Vectors_for_Word_Representation_converted.pdf...\n",
      "Cleaning Data_Management_-_1_Trifacta_Tutorial_Document_converted.pdf...\n",
      "Cleaning Data_Management_1.ADSA.TS_converted.pdf...\n",
      "Cleaning Mask_R-CNN_converted.pdf...\n",
      "Cleaning LSTM_-_A_Search_Space_Odyssey_converted.pdf...\n",
      "Cleaning NIST.AI.100-1_converted.pdf...\n",
      "Cleaning masteringtableau2021_converted.pdf...\n",
      "Cleaning NY_Times_-_ClearView_AI_converted.pdf...\n",
      "Cleaning NIST.AI.100-2e2023_converted.pdf...\n",
      "Cleaning One-Shot_Learning_of_Object_Categories_converted.pdf...\n",
      "Cleaning OpenRefine-tutorial-v1.5_converted.pdf...\n",
      "Cleaning privacybook_converted.pdf...\n",
      "Cleaning Return_of_Frustratingly_Easy_Domain_Adaptation_converted.pdf...\n",
      "Cleaning scraped_detailed_data.pdf...\n",
      "Cleaning Task_Clustering_and_Gating_for_Bayesian_Multitask_Learning_converted.pdf...\n",
      "Cleaning Theory_Session_3_converted.pdf...\n",
      "Cleaning Theory.Session_1_converted.pdf...\n",
      "Cleaning Theory.Session_10_converted.pdf...\n",
      "Cleaning Theory.Session_11_converted.pdf...\n",
      "Cleaning Theory.Session_12_converted.pdf...\n",
      "Cleaning Theory.Session_2_converted.pdf...\n",
      "Cleaning Theory.Session_4_converted.pdf...\n",
      "Cleaning Theory.Session_5_converted.pdf...\n",
      "Cleaning Theory.Session_6_converted.pdf...\n",
      "Cleaning Theory.Session_7_converted.pdf...\n",
      "Cleaning Theory.Session_7.Supplement.SRH_Clustering.BDBA_converted.pdf...\n",
      "Cleaning Theory.Session_8_converted.pdf...\n",
      "Cleaning Theory.Session_8.Supplement.SRH_Regression.BDBA_converted.pdf...\n",
      "Cleaning Theory.Session_9_converted.pdf...\n",
      "Cleaning YOLOv3_converted.pdf...\n",
      "Cleaning Understanding_the_difficulty_of_training_deep_feedforward_neural_networks_converted.pdf...\n",
      "Cleaning Universal_Transfer_Learning_converted.pdf...\n",
      "Cleaning wp-malicious-uses-and-abuses-of-artificial-intelligence_converted.pdf...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "from reportlab.pdfgen import canvas\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove unwanted symbols and multiple spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove all symbols except word characters and spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)     # Replace multiple spaces with a single space\n",
    "    return text.strip()                  # Strip leading and trailing spaces\n",
    "\n",
    "def clean_file_name(original_name):\n",
    "    # Remove numbers, underscores, hyphens and add \"_cleaned\" at the end of the file name\n",
    "    cleaned_name = re.sub(r'[\\d_-]', '', original_name)  # Remove numbers, underscores, and hyphens\n",
    "    cleaned_name = cleaned_name.strip()                   # Remove any leading/trailing spaces\n",
    "    cleaned_name += '_cleaned.pdf'                        # Append \"_cleaned.pdf\"\n",
    "    return cleaned_name\n",
    "\n",
    "def create_cleaned_pdf(output_path, cleaned_text):\n",
    "    # Create a new PDF file with cleaned text\n",
    "    c = canvas.Canvas(output_path)\n",
    "    lines = cleaned_text.split('\\n')\n",
    "    y = 800  # Starting height for text\n",
    "\n",
    "    for line in lines:\n",
    "        c.drawString(50, y, line)  # Draw each line of text\n",
    "        y -= 20  # Move down for the next line\n",
    "        if y < 50:  # Check if we are near the bottom of the page\n",
    "            c.showPage()  # Create a new page\n",
    "            y = 800  # Reset y position\n",
    "\n",
    "    c.save()\n",
    "\n",
    "def clean_pdf(input_pdf_path, output_folder):\n",
    "    reader = PdfReader(input_pdf_path)\n",
    "    cleaned_text = \"\"\n",
    "\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            cleaned_text += clean_text(text) + \"\\n\"  # Append cleaned text from each page\n",
    "\n",
    "    # Clean the original file name and create a new output path\n",
    "    original_name = os.path.basename(input_pdf_path)\n",
    "    cleaned_name = clean_file_name(original_name)\n",
    "    output_pdf_path = os.path.join(output_folder, cleaned_name)\n",
    "\n",
    "    # Create a new cleaned PDF\n",
    "    create_cleaned_pdf(output_pdf_path, cleaned_text)\n",
    "\n",
    "def clean_pdfs_in_folder(folder_path, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Create output folder if it doesn't exist\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            print(f\"Cleaning {filename}...\")\n",
    "            clean_pdf(os.path.join(folder_path, filename), output_folder)\n",
    "\n",
    "# Specify the folder containing your PDFs and the output folder for cleaned PDFs\n",
    "folder_path = 'Dataset'  # Update this to your folder path\n",
    "output_folder = 'Data_Cleaned'  # Update this to your desired output folder\n",
    "clean_pdfs_in_folder(folder_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "py2GlL8eKNzo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
